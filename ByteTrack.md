# ByteTrack: 多目标跟踪通过关联每一个检测框

# *ByteTrack: Multi-Object Tracking by Associating Every Detection Box*

## Abstrack

多目标跟踪（MOT）旨在评估视频中的物体的检测框和目标ID. 大多数方法获取目标ID通常是关联大于阈值的高分值的检测框。但是对于低分值的检测框，比如遮挡的目标，被简单的丢弃，这将会带来不可忽略的真实目标的丢失和碎片化的轨迹。 为了解决这种问题，我们提出了一个简单的，有效的，通用的方法，通过跟踪每一个检测框来代替只跟踪高分值的检测框。对于低分值的检测框，我们使用他们轨迹的相似性去关联、跟踪恢复真实目标，并过滤背景的检测框。

在9个不同的state-of-the-art的tracker方法中，我们的方法均在其基础上提升了1-10个百分点。为了提升the-state-of-the-art of MOT方法的性能，我们设计了一个简单的，强壮tracker,并命名为**ByteTrack**.  首先，我们在MOT数据集上实现了80.3MOTE, 77.3IDF1, 63.1HOTA， 30FPS 在单个V100GPU上。ByteTrack还实现了在MOT20，HiEve和BDD100K数据集上的跟踪的benchmarks。

这个源代码和用于部署的其他版本预训练模型以及教程均发布在github上。

## 1. Introduction

Tracking-by-detection 是当前有效的对目标跟踪范式。由于视频场景的复杂性，检测器可能预测出不完美的检测框。现有比较优秀的MOT方法需要通过计算true-prositive/false-positive来权衡检测框，并消除低置信度的框。然而，这种消除低置信度的检测框的方法真的是对的吗？我们的回答是:NO!. 就像黑格尔说的那样“合理的就是真实的，真实的才是合理的”。低置信度的检测框有时候隐示了存在的目标，例如目标被遮挡。过滤到这些目标将对MOT任务造成不可挽回的错误，带来不可不略的缺失检测和碎片化轨迹。

FIgure 2(a) 和（b）显示了这个问题。在frame t1中，我们利用三个不同的轨迹作为他们的分数（都高于0.5）。然而，在frame t2和frame t3中这个遮挡出现了，红色的轨迹框对应的检测分数变低了（0.8->0.4， 0.4->0.1）。这些检测框通过阈值被清除，红色检测框的轨迹也随之消失。然而，如果我们使用每一个检测框，更多的false-positive会被立即引入，例如:最右侧的frame t3 in Figure2a。据我们所知，在MOT中很少有方法能够处理这种检测困境。

在本文中，我们发现，在低分检测框中，轨迹的相似性为区分检测框和背景提供能了强有力的线索。正如Figure2c所示，通过使用模型预测运动的检测框，两个低分的检测框被匹配到了跟踪路线中，并且这个目标也被正确的恢复。同事，这个背景框被删除了，因为它没有被匹配的路径。

为了在匹配过程中充分使用高分和低分检测框，我们提出了一种简单有效的关联方法--BYTE， 以每个检测框都是跟踪轨迹的一个基本单元，在计算机中成为字节， 我们跟踪的方法对每个详细的检测框进行充分利用。我们**首先**对使用高分的检测框，使用基于运动相似行和外观相似性的方法来匹配轨迹。与文献[6]相同，我们采用卡尔曼滤波方法来预测下一帧的轨迹位置。这个相似性可以使用IoU方法和Re-ID方法来解决这个预测框和检测框之间的距离。Figure2b正是第一次匹配后的结果。**然后**我们使用相同的运动相似行方法执行第二次匹配，为未被匹配的轨迹（红色框中的轨迹）和低分值检测框进行匹配。Figure2c显示了第二次匹配的结果。有着比较低的检测分数的被遮挡的人被正确的匹配先前的路径，并且右边的背景框被移除。

作为这个目标检测和关联的集成话题，MOT理想的解决办法永远不是一个检测器和以下内容相关联；此外，设计好他们的连接区域也是非常重要的。BYTE的创新之处在于检测区域和关联的交界处，低分检测盒是连接提升他们的桥梁。受益于这种集成创新，当BYTE应用于9个不同的最先进的跟踪器，包括基于Re-ID的方法（33，37，69，85），基于运动的方法（71，89），基于chain的（48）和基于attention的方法（59， 80），几乎在所有的指标上都取得了显著的改进，包括MOTE, IDF1分数和ID switches。例如，我们提升了CenterTrack(89)的MOTA指标从66.1到67.4， IDF1从64.2到74.0，在MOT17的半验证集上将ID从528降低到144。

向着提升MOT的the-state-of-the-art，我们提出了一个简单并强大跟踪方法，叫做ByteTrack. 我们采用了一个最新的高性能的检测器YOLO-X去包含检测框和关联他们，用我们的方法BYTE。在MOT挑战中，在MOT17和MOT20数据集上ByteTrack的性能第一，实现了80.3MOTA, 77.3IDF1和63.1HOTA, 30FPPS在单张V100GUP上。and 77.8 MOTA, 75.2 IDF1 and 61.3 HOTA on much more crowded MOT20。ByteTrack在HiEve和BDD100K数据集上也实现了state-of-the-art的表现。我们希望这个有效的简单的方法ByteTrack可以在实际应用和社会计算中更具有吸引力。

## 2. Relate Word

### 2.1 目标检测 in MOT

目标检测是计算机视觉中最活跃的研究课题之一，是实现多目标跟踪的基础。这个MOT17数据集提供了检测结果包含受欢迎的检测器例如DPM, Faster R-CNN和SDP。很多的方法（3，9，12，14，28，74，91）重点关注基于给出的检测结果提升跟踪的性能。

**Tracking by detection.** 随着目标检测的快速发展，越来越多的方法开始使用更加优秀的检测器来获得跟高的跟踪性能。One-stage目标检测RetinaNet开始被数几种方法所采用（39，48）。CenterNet因为他的有效性和高效性因此被最大多数方法所采用的检测器（63，65，67，71，85，87，89）。YOLO系列由于它的准确性和速度也是特别受欢迎的算法。这些方法大多数都采用直接检测框在单张图片上进行跟踪。

然而，（41，62）指出在视频目标检测方法中，在视频序列中当遮挡物或者运动模糊发生时，缺失检测的数量和较低的检测分数会逐渐增多。因此，通常利用前一帧的信息来提高视频检测的性能。

**Detection by trakcing.** 还可以使用跟踪来获取更准确的检测框。一些方法（12，13，14，15，53，91）使用但目标跟踪（SOT）（5）和卡尔曼滤波（29）来预测目标轨迹的在下一帧中的位置，并将下一帧预测框和检测框进行融合来增强检测结果。其他方法（34，86）利用前一帧的跟踪狂来增强下一帧的特征表示。最近，基于transformer的检测器（11，92）也被这几种方法（20，38，64，66）来增强帧间的传播盒能力。我们的方法利用轨迹的相似性来增强检测框的预测能力。

各个检测器在获取检测框之后，大多数MOT方法（33，39，47，59，69，71，85）为了使检测框有着较高的置信度，使用0.5作为阈值，并且将这些框作为数据关联的收入。这是因为较低的置信度的检测框包含着很多会影响跟踪性能的背景。然而，我们发现被遮挡的目标可以正确的被检测，但是有着较低的分数，为了减少缺失的检测框并保持轨迹的连续性，我们使用所有的检测结果并且将他们相互关联。

### 2.2 数据关联

数据关联是多目标跟踪的核心，它首先计算轨迹和检测框的相似性，并且根据他们的相似度来利用不同的策略的来匹配。

**Similarity metrics.**  位置，运动和外观对关联是非常有用的。SORT(6)方法用一种简单的方式结合了位置和运动线索。它首先利用Kalman-filter去预测下一帧轨迹的位置，然后计算检测框和预测框之间的IoU作为他们之间的相似性。一些最近的方法（59，71，89）设计出网络来学习目标运动的信息，并在相机较大的移动或者较小的帧率下计算鲁棒性。位置和运动的相似性是准确的



